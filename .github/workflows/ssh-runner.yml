name: SSH into our runners
on:
  workflow_dispatch:
    inputs:
      runner_type:
        description: Type of runner to test (a10)
        required: true
      docker_image:
        description: Name of the Docker image
        required: true
      num_gpus:
        description: Type of the number of gpus to use (`single` or `multi`)
        required: true
env:
  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}
  HF_HOME: /mnt/cache
  TRANSFORMERS_IS_CI: yes
  OMP_NUM_THREADS: 8
  MKL_NUM_THREADS: 8
  RUN_SLOW: yes
  TF_FORCE_GPU_ALLOW_GROWTH: true
  CUDA_VISIBLE_DEVICES: 0,1
jobs:
  get_runner:
    name: Get runner to use
    runs-on: ubuntu-latest
    outputs:
      RUNNER: ${{ steps.set_runner.outputs.RUNNER }}
    steps:
    - name: Get runner to use
      shell: bash
      env:
        NUM_GPUS: ${{ github.event.inputs.num_gpus }}
        RUNNER_TYPE: ${{ github.event.inputs.runner_type }}
      run: "if [[ \"$NUM_GPUS\" == \"single\" && \"$RUNNER_TYPE\" == \"a10\" ]]; then\n\
        \  echo \"RUNNER=aws-g5-4xlarge-cache-ssh\" >> $GITHUB_ENV\nelif [[ \"$NUM_GPUS\"\
        \ == \"multi\" && \"$RUNNER_TYPE\" == \"a10\" ]]; then\n  echo \"RUNNER=aws-g5-12xlarge-cache-ssh\"\
        \ >> $GITHUB_ENV\nelse\n  echo \"RUNNER=\" >> $GITHUB_ENV\nfi\n"
    - name: Set runner to use
      id: set_runner
      run: 'echo "$RUNNER"

        echo "RUNNER=$RUNNER" >> $GITHUB_OUTPUT

        '
  ssh_runner:
    name: SSH
    needs: get_runner
    runs-on: ubuntu-latest
    container:
      image: ${{ github.event.inputs.docker_image }}
    steps:
    - name: Update clone
      working-directory: /transformers
      env:
        commit_sha: ${{ github.sha }}
      run: 'git fetch && git checkout "$commit_sha"

        '
    - name: Cleanup
      working-directory: /transformers
      run: 'rm -rf tests/__pycache__

        rm -rf tests/models/__pycache__

        rm -rf reports

        '
    - name: Show installed libraries and their versions
      working-directory: /transformers
      run: pip freeze
    - name: NVIDIA-SMI
      run: 'nvidia-smi

        '
    - name: Create python alias
      run: "ln -sf $(which python3) /usr/local/bin/python\nln -sf $(which pip3) /usr/local/bin/pip\n\
        echo \"\u2705 python -> python3 symlink created\"\n"
    - name: Install psutil for memory monitor
      run: 'pip install psutil --break-system-packages

        '
    - name: Download memory monitor script
      working-directory: /transformers
      run: 'apt-get update && apt-get install -y curl

        curl -o memory_monitor.py https://raw.githubusercontent.com/huggingface/transformers/refs/heads/utility_scripts/utils/memory_monitor.py

        '
    - name: Start memory monitor
      working-directory: /transformers
      continue-on-error: true
      run: 'python3 memory_monitor.py --threshold 90 --interval 1 > memory_monitor.log
        2>&1 &

        echo $! > memory_monitor.pid

        echo "Memory monitor started with PID $(cat memory_monitor.pid)"

        # Give it a moment to start

        sleep 2

        # Verify it''s running

        ps aux | grep memory_monitor | grep -v grep || echo "Warning: memory monitor
        may not be running"

        '
    - name: Install utilities
      run: 'apt-get install -y nano

        '
    - name: Store Slack infos
      shell: bash
      env:
        GITHUB_ACTOR: ${{ github.actor }}
      run: 'echo "$GITHUB_ACTOR"

        github_actor=$GITHUB_ACTOR

        github_actor=${github_actor/''-''/''_''}

        echo "$github_actor"

        echo "github_actor=$github_actor" >> $GITHUB_ENV

        '
    - name: Setup automatic environment for SSH login
      run: "# Create shared environment setup\ncat > /root/.env_setup << 'EOF'\n#\
        \ Auto-setup (non-sensitive vars)\nexport HF_HOME=/mnt/cache\nexport TRANSFORMERS_IS_CI=yes\n\
        export OMP_NUM_THREADS=8\nexport MKL_NUM_THREADS=8\nexport RUN_SLOW=yes\n\
        export TF_FORCE_GPU_ALLOW_GROWTH=true\nexport CUDA_VISIBLE_DEVICES=0,1\n\n\
        cd /transformers 2>/dev/null || true\n\n# Remind user to set token if needed\n\
        if [ -z \"$HF_HUB_READ_TOKEN\" ]; then\n    echo \"\u26A0\uFE0F  HF_HUB_READ_TOKEN\
        \ not set. Set it with:\"\n    echo \"    export HF_HUB_READ_TOKEN=hf_xxxxx\"\
        \nelse\n    echo \"\u2705 HF_HUB_READ_TOKEN is set\"\nfi\n\necho \"\U0001F4C1\
        \ Working directory: $(pwd)\"\nEOF\n\n# Source from both .bash_profile and\
        \ .bashrc\necho 'source /root/.env_setup' >> /root/.bash_profile\necho 'source\
        \ /root/.env_setup' >> /root/.bashrc\n"
    - name: Store Slack infos
      shell: bash
      env:
        user_slack_id: ${{ secrets[format('{0}_{1}', env.github_actor, 'SLACK_ID')]
          }}
        default_slack_channel: ${{ secrets.SLACK_CIFEEDBACK_CHANNEL }}
      run: "echo \"$github_actor\"\nif [ \"$user_slack_id\" != \"\" ]; then\n  echo\
        \ \"SLACKCHANNEL=$user_slack_id\" >> $GITHUB_ENV\nelse\n  echo \"SLACKCHANNEL=$default_slack_channel\"\
        \ >> $GITHUB_ENV\nfi\n"
    - name: Tailscale
      uses: huggingface/tailscale-action@main
      with:
        authkey: ${{ secrets.TAILSCALE_SSH_AUTHKEY }}
        slackChannel: ${{ env.SLACKCHANNEL }}
        slackToken: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}
        waitForSSH: true
        sshTimeout: 15m
