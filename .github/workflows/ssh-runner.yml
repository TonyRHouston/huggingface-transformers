name: SSH into our runners
on:
  push:
    branches:
    - ssh_new_cluster
env:
  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}
  HF_HOME: /mnt/cache
  TRANSFORMERS_IS_CI: yes
  OMP_NUM_THREADS: 8
  MKL_NUM_THREADS: 8
  RUN_SLOW: yes
  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}
  TF_FORCE_GPU_ALLOW_GROWTH: true
  CUDA_VISIBLE_DEVICES: 0,1
  RUN_PT_TF_CROSS_TESTS: 1
jobs:
  ssh_runner:
    name: SSH
    runs-on: ubuntu-latest
    container:
      image: huggingface/transformers-all-latest-gpu
      options: --gpus all --privileged --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/
    steps:
    - name: Update clone
      working-directory: /transformers
      run: 'git fetch && git checkout ${{ github.sha }}

        '
    - name: Cleanup
      working-directory: /transformers
      run: 'rm -rf tests/__pycache__

        rm -rf tests/models/__pycache__

        rm -rf reports

        '
    - name: Show installed libraries and their versions
      working-directory: /transformers
      run: pip freeze
    - name: NVIDIA-SMI
      run: 'nvidia-smi

        '
    - name: Tailscale
      uses: huggingface/tailscale-action@main
      with:
        authkey: ${{ secrets.TAILSCALE_SSH_AUTHKEY }}
        slackChannel: ${{ secrets.SLACK_CIFEEDBACK_CHANNEL }}
        slackToken: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}
        waitForSSH: true
        sshTimeout: 30m
